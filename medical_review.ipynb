{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import string\n",
    "random.seed(123)\n",
    "import datetime as dt\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore','RuntimeWarning')\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.collocations import BigramCollocationFinder, TrigramCollocationFinder\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = open('EMR text files/Adam Pie.txt','r',encoding='latin').readlines()\n",
    "f2 = open('EMR text files/Bill Windows.txt','r',encoding='latin').readlines()\n",
    "f3 = open('EMR text files/Billy Gato.txt','r',encoding='latin').readlines()\n",
    "f4 = open('EMR text files/Cherie Amore.txt','r',encoding='latin').readlines()\n",
    "f5 = open('EMR text files/John Donut.txt','r',encoding='latin').readlines()\n",
    "f6 = open('EMR text files/Monica Latte.txt','r',encoding='latin').readlines()\n",
    "f7 = open('EMR text files/Steve Apple.txt','r',encoding='latin').readlines()\n",
    "f8 = open('EMR text files/Tom Gellato.txt','r',encoding='latin').readlines()\n",
    "f9 = open('EMR text files/Wendy See.txt','r',encoding='latin').readlines()\n",
    "\n",
    "names=['Adam Pie','Bill Windows','Billy Gato','Cherie Amore','John Donut','Monica Latte','Steve Apple','Tom Gellato','Wendy See']\n",
    "\n",
    "Document = [f1,f2,f3,f4,f5,f6,f7,f8,f9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.DataFrame({'names':names,'document':Document})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adam Pie</td>\n",
       "      <td>[Use for January 2011 abstraction\\n, \\n, WeSer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bill Windows</td>\n",
       "      <td>[Use for April 2011 abstraction \\n, \\n, WeServ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Billy Gato</td>\n",
       "      <td>[Use for October 2010 abstraction\\n, \\n, WeSer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cherie Amore</td>\n",
       "      <td>[Use for October 2010 abstraction\\n, \\n, WeSer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John Donut</td>\n",
       "      <td>[WeServeEveryone Clinic\\t \\n, 1111 First Stree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Monica Latte</td>\n",
       "      <td>[WeServeEveryone Clinic\\t \\n, 1111 First Stree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Steve Apple</td>\n",
       "      <td>[Use for April 2011 abstraction\\n, \\n, WeServe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tom Gellato</td>\n",
       "      <td>[Use for January 2011 abstraction\\n, \\n, WeSer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wendy See</td>\n",
       "      <td>[Use for October 2010 abstraction \\n, \\n, WeSe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          names                                           document\n",
       "0      Adam Pie  [Use for January 2011 abstraction\\n, \\n, WeSer...\n",
       "1  Bill Windows  [Use for April 2011 abstraction \\n, \\n, WeServ...\n",
       "2    Billy Gato  [Use for October 2010 abstraction\\n, \\n, WeSer...\n",
       "3  Cherie Amore  [Use for October 2010 abstraction\\n, \\n, WeSer...\n",
       "4    John Donut  [WeServeEveryone Clinic\\t \\n, 1111 First Stree...\n",
       "5  Monica Latte  [WeServeEveryone Clinic\\t \\n, 1111 First Stree...\n",
       "6   Steve Apple  [Use for April 2011 abstraction\\n, \\n, WeServe...\n",
       "7   Tom Gellato  [Use for January 2011 abstraction\\n, \\n, WeSer...\n",
       "8     Wendy See  [Use for October 2010 abstraction \\n, \\n, WeSe..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Preprocess the Reviews\n",
    "def clean_doc(doc):\n",
    "    \n",
    "    # Tokenization\n",
    "    tokens = doc.split(' ')\n",
    "    \n",
    "    # Converting into lower case\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    \n",
    "    # Punctuation removal\n",
    "    tokens = [re.sub(r\"[^a-zA-Z#\\s]\",'',i) for i in tokens]\n",
    "    tokens = [re.sub(r\"[\\r\\n\\t]\",'',i) for i in tokens]\n",
    "    \n",
    "    # Stopwords removal\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    \n",
    "    # Lemmatization\n",
    "    lmtzr = nltk.stem.WordNetLemmatizer()\n",
    "    tokens = [lmtzr.lemmatize(w) for w in tokens]\n",
    "    \n",
    "    # Stemming\n",
    "    stemmer = nltk.stem.SnowballStemmer('english')\n",
    "    tokens = [stemmer.stem(w) for w in tokens]\n",
    "    \n",
    "    # filter out short tokens\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame['modified_document'] = data_frame['document'].apply(lambda x: [clean_doc(each_line) for each_line in x] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [[use, januari, abstract], [], [weserveeveryon...\n",
       "1    [[use, april, abstract], [], [weserveeveryon, ...\n",
       "2    [[use, octob, abstract], [], [weserveeveryon, ...\n",
       "3    [[use, octob, abstract], [], [weserveeveryon, ...\n",
       "4    [[weserveeveryon, clinic], [first, street, cal...\n",
       "5    [[weserveeveryon, clinic], [first, street, cal...\n",
       "6    [[use, april, abstract], [], [weserveeveryon, ...\n",
       "7    [[use, januari, abstract], [], [weserveeveryon...\n",
       "8    [[use, octob, abstract], [], [weserveeveryon, ...\n",
       "Name: modified_document, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame['modified_document']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame['modified_document'] = data_frame['modified_document'].apply(lambda x: [x1 for xs in x for x1 in xs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>document</th>\n",
       "      <th>modified_document</th>\n",
       "      <th>Document_except_rare_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adam Pie</td>\n",
       "      <td>[Use for January 2011 abstraction\\n, \\n, WeSer...</td>\n",
       "      <td>[use, januari, abstract, weserveeveryon, clini...</td>\n",
       "      <td>[soc, hiv, reason, temp, club, sub, advers, ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bill Windows</td>\n",
       "      <td>[Use for April 2011 abstraction \\n, \\n, WeServ...</td>\n",
       "      <td>[use, april, abstract, weserveeveryon, clinic,...</td>\n",
       "      <td>[soc, hiv, reason, temp, sub, advers, routin, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Billy Gato</td>\n",
       "      <td>[Use for October 2010 abstraction\\n, \\n, WeSer...</td>\n",
       "      <td>[use, octob, abstract, weserveeveryon, clinic,...</td>\n",
       "      <td>[soc, hiv, reason, temp, club, sub, advers, ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cherie Amore</td>\n",
       "      <td>[Use for October 2010 abstraction\\n, \\n, WeSer...</td>\n",
       "      <td>[use, octob, abstract, weserveeveryon, clinic,...</td>\n",
       "      <td>[soc, hiv, reason, temp, sub, advers, routin, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John Donut</td>\n",
       "      <td>[WeServeEveryone Clinic\\t \\n, 1111 First Stree...</td>\n",
       "      <td>[weserveeveryon, clinic, first, street, califo...</td>\n",
       "      <td>[soc, hiv, reason, temp, club, sub, advers, ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Monica Latte</td>\n",
       "      <td>[WeServeEveryone Clinic\\t \\n, 1111 First Stree...</td>\n",
       "      <td>[weserveeveryon, clinic, first, street, califo...</td>\n",
       "      <td>[soc, hiv, reason, temp, club, sub, advers, ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Steve Apple</td>\n",
       "      <td>[Use for April 2011 abstraction\\n, \\n, WeServe...</td>\n",
       "      <td>[use, april, abstract, weserveeveryon, clinic,...</td>\n",
       "      <td>[soc, hiv, reason, temp, club, sub, advers, ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tom Gellato</td>\n",
       "      <td>[Use for January 2011 abstraction\\n, \\n, WeSer...</td>\n",
       "      <td>[use, januari, abstract, weserveeveryon, clini...</td>\n",
       "      <td>[soc, hiv, reason, temp, club, sub, advers, ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wendy See</td>\n",
       "      <td>[Use for October 2010 abstraction \\n, \\n, WeSe...</td>\n",
       "      <td>[use, octob, abstract, weserveeveryon, clinic,...</td>\n",
       "      <td>[soc, hiv, reason, temp, club, sub, advers, ro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          names                                           document  \\\n",
       "0      Adam Pie  [Use for January 2011 abstraction\\n, \\n, WeSer...   \n",
       "1  Bill Windows  [Use for April 2011 abstraction \\n, \\n, WeServ...   \n",
       "2    Billy Gato  [Use for October 2010 abstraction\\n, \\n, WeSer...   \n",
       "3  Cherie Amore  [Use for October 2010 abstraction\\n, \\n, WeSer...   \n",
       "4    John Donut  [WeServeEveryone Clinic\\t \\n, 1111 First Stree...   \n",
       "5  Monica Latte  [WeServeEveryone Clinic\\t \\n, 1111 First Stree...   \n",
       "6   Steve Apple  [Use for April 2011 abstraction\\n, \\n, WeServe...   \n",
       "7   Tom Gellato  [Use for January 2011 abstraction\\n, \\n, WeSer...   \n",
       "8     Wendy See  [Use for October 2010 abstraction \\n, \\n, WeSe...   \n",
       "\n",
       "                                   modified_document  \\\n",
       "0  [use, januari, abstract, weserveeveryon, clini...   \n",
       "1  [use, april, abstract, weserveeveryon, clinic,...   \n",
       "2  [use, octob, abstract, weserveeveryon, clinic,...   \n",
       "3  [use, octob, abstract, weserveeveryon, clinic,...   \n",
       "4  [weserveeveryon, clinic, first, street, califo...   \n",
       "5  [weserveeveryon, clinic, first, street, califo...   \n",
       "6  [use, april, abstract, weserveeveryon, clinic,...   \n",
       "7  [use, januari, abstract, weserveeveryon, clini...   \n",
       "8  [use, octob, abstract, weserveeveryon, clinic,...   \n",
       "\n",
       "                           Document_except_rare_freq  \n",
       "0  [soc, hiv, reason, temp, club, sub, advers, ro...  \n",
       "1  [soc, hiv, reason, temp, sub, advers, routin, ...  \n",
       "2  [soc, hiv, reason, temp, club, sub, advers, ro...  \n",
       "3  [soc, hiv, reason, temp, sub, advers, routin, ...  \n",
       "4  [soc, hiv, reason, temp, club, sub, advers, ro...  \n",
       "5  [soc, hiv, reason, temp, club, sub, advers, ro...  \n",
       "6  [soc, hiv, reason, temp, club, sub, advers, ro...  \n",
       "7  [soc, hiv, reason, temp, club, sub, advers, ro...  \n",
       "8  [soc, hiv, reason, temp, club, sub, advers, ro...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert nested lists to single list\n",
    "def unlist_words(a):\n",
    "    temp = [x for xs in a for x in xs]\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = unlist_words(data_frame['modified_document'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5426"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = nltk.FreqDist(corpus)\n",
    "d = pd.DataFrame({'Word': list(a.keys()),\n",
    "                  'Count': list(a.values())})\n",
    "frequent_words = d.nlargest(columns=\"Count\", n = 350)\n",
    "rare_words = d.nsmallest(columns=\"Count\", n = 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame['Document_except_rare_freq'] = data_frame['modified_document'].apply(lambda x: list((set(x)-set(rare_words.Word))-set(frequent_words.Word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>document</th>\n",
       "      <th>modified_document</th>\n",
       "      <th>Document_except_rare_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adam Pie</td>\n",
       "      <td>[Use for January 2011 abstraction\\n, \\n, WeSer...</td>\n",
       "      <td>[use, januari, abstract, weserveeveryon, clini...</td>\n",
       "      <td>[neg, bhi, microalb, urn, race, lab, social, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bill Windows</td>\n",
       "      <td>[Use for April 2011 abstraction \\n, \\n, WeServ...</td>\n",
       "      <td>[use, april, abstract, weserveeveryon, clinic,...</td>\n",
       "      <td>[flowsheet, night, hypoglycem, account, bill, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Billy Gato</td>\n",
       "      <td>[Use for October 2010 abstraction\\n, \\n, WeSer...</td>\n",
       "      <td>[use, octob, abstract, weserveeveryon, clinic,...</td>\n",
       "      <td>[neg, lab, race, social, monitor, report, acco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cherie Amore</td>\n",
       "      <td>[Use for October 2010 abstraction\\n, \\n, WeSer...</td>\n",
       "      <td>[use, octob, abstract, weserveeveryon, clinic,...</td>\n",
       "      <td>[social, account, millennium, glucos, consult,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John Donut</td>\n",
       "      <td>[WeServeEveryone Clinic\\t \\n, 1111 First Stree...</td>\n",
       "      <td>[weserveeveryon, clinic, first, street, califo...</td>\n",
       "      <td>[neg, bhi, microalb, urn, lab, race, monitor, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Monica Latte</td>\n",
       "      <td>[WeServeEveryone Clinic\\t \\n, 1111 First Stree...</td>\n",
       "      <td>[weserveeveryon, clinic, first, street, califo...</td>\n",
       "      <td>[lisinopril, auscult, report, glucos, microalb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Steve Apple</td>\n",
       "      <td>[Use for April 2011 abstraction\\n, \\n, WeServe...</td>\n",
       "      <td>[use, april, abstract, weserveeveryon, clinic,...</td>\n",
       "      <td>[flowsheet, lisinopril, marri, neg, steve, per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tom Gellato</td>\n",
       "      <td>[Use for January 2011 abstraction\\n, \\n, WeSer...</td>\n",
       "      <td>[use, januari, abstract, weserveeveryon, clini...</td>\n",
       "      <td>[neg, tom, microalb, urn, race, social, monito...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wendy See</td>\n",
       "      <td>[Use for October 2010 abstraction \\n, \\n, WeSe...</td>\n",
       "      <td>[use, octob, abstract, weserveeveryon, clinic,...</td>\n",
       "      <td>[social, cap, report, millennium, health, lowe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          names                                           document  \\\n",
       "0      Adam Pie  [Use for January 2011 abstraction\\n, \\n, WeSer...   \n",
       "1  Bill Windows  [Use for April 2011 abstraction \\n, \\n, WeServ...   \n",
       "2    Billy Gato  [Use for October 2010 abstraction\\n, \\n, WeSer...   \n",
       "3  Cherie Amore  [Use for October 2010 abstraction\\n, \\n, WeSer...   \n",
       "4    John Donut  [WeServeEveryone Clinic\\t \\n, 1111 First Stree...   \n",
       "5  Monica Latte  [WeServeEveryone Clinic\\t \\n, 1111 First Stree...   \n",
       "6   Steve Apple  [Use for April 2011 abstraction\\n, \\n, WeServe...   \n",
       "7   Tom Gellato  [Use for January 2011 abstraction\\n, \\n, WeSer...   \n",
       "8     Wendy See  [Use for October 2010 abstraction \\n, \\n, WeSe...   \n",
       "\n",
       "                                   modified_document  \\\n",
       "0  [use, januari, abstract, weserveeveryon, clini...   \n",
       "1  [use, april, abstract, weserveeveryon, clinic,...   \n",
       "2  [use, octob, abstract, weserveeveryon, clinic,...   \n",
       "3  [use, octob, abstract, weserveeveryon, clinic,...   \n",
       "4  [weserveeveryon, clinic, first, street, califo...   \n",
       "5  [weserveeveryon, clinic, first, street, califo...   \n",
       "6  [use, april, abstract, weserveeveryon, clinic,...   \n",
       "7  [use, januari, abstract, weserveeveryon, clini...   \n",
       "8  [use, octob, abstract, weserveeveryon, clinic,...   \n",
       "\n",
       "                           Document_except_rare_freq  \n",
       "0  [neg, bhi, microalb, urn, race, lab, social, m...  \n",
       "1  [flowsheet, night, hypoglycem, account, bill, ...  \n",
       "2  [neg, lab, race, social, monitor, report, acco...  \n",
       "3  [social, account, millennium, glucos, consult,...  \n",
       "4  [neg, bhi, microalb, urn, lab, race, monitor, ...  \n",
       "5  [lisinopril, auscult, report, glucos, microalb...  \n",
       "6  [flowsheet, lisinopril, marri, neg, steve, per...  \n",
       "7  [neg, tom, microalb, urn, race, social, monito...  \n",
       "8  [social, cap, report, millennium, health, lowe...  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngrams\n",
    "def ngrams(CollocationFinder,x):\n",
    "    a = CollocationFinder.from_words(x).ngram_fd\n",
    "    d = pd.DataFrame({'ngrams': list(a.keys()),\n",
    "                  'Count': list(a.values())})\n",
    "    # selecting top 25 bigrams     \n",
    "    ngrams = d.nlargest(columns=\"Count\", n = 25)\n",
    "    return ngrams.ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame['bigrams'] = data_frame['Document_except_rare_freq'].apply(lambda x: list(ngrams(BigramCollocationFinder,x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame['trigrams'] = data_frame['Document_except_rare_freq'].apply(lambda x: list(ngrams(TrigramCollocationFinder,x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>document</th>\n",
       "      <th>modified_document</th>\n",
       "      <th>Document_except_rare_freq</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adam Pie</td>\n",
       "      <td>[Use for January 2011 abstraction\\n, \\n, WeSer...</td>\n",
       "      <td>[use, januari, abstract, weserveeveryon, clini...</td>\n",
       "      <td>[neg, bhi, microalb, urn, race, lab, social, m...</td>\n",
       "      <td>[(neg, bhi), (bhi, microalb), (microalb, urn),...</td>\n",
       "      <td>[(neg, bhi, microalb), (bhi, microalb, urn), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bill Windows</td>\n",
       "      <td>[Use for April 2011 abstraction \\n, \\n, WeServ...</td>\n",
       "      <td>[use, april, abstract, weserveeveryon, clinic,...</td>\n",
       "      <td>[flowsheet, night, hypoglycem, account, bill, ...</td>\n",
       "      <td>[(flowsheet, night), (night, hypoglycem), (hyp...</td>\n",
       "      <td>[(flowsheet, night, hypoglycem), (night, hypog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Billy Gato</td>\n",
       "      <td>[Use for October 2010 abstraction\\n, \\n, WeSer...</td>\n",
       "      <td>[use, octob, abstract, weserveeveryon, clinic,...</td>\n",
       "      <td>[neg, lab, race, social, monitor, report, acco...</td>\n",
       "      <td>[(neg, lab), (ago, year), (ophthalmolog, lower...</td>\n",
       "      <td>[(neg, lab, race), (lab, race, social), (percu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cherie Amore</td>\n",
       "      <td>[Use for October 2010 abstraction\\n, \\n, WeSer...</td>\n",
       "      <td>[use, octob, abstract, weserveeveryon, clinic,...</td>\n",
       "      <td>[social, account, millennium, glucos, consult,...</td>\n",
       "      <td>[(social, account), (account, millennium), (mi...</td>\n",
       "      <td>[(social, account, millennium), (account, mill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John Donut</td>\n",
       "      <td>[WeServeEveryone Clinic\\t \\n, 1111 First Stree...</td>\n",
       "      <td>[weserveeveryon, clinic, first, street, califo...</td>\n",
       "      <td>[neg, bhi, microalb, urn, lab, race, monitor, ...</td>\n",
       "      <td>[(neg, bhi), (lisinopril, better), (ophthalmol...</td>\n",
       "      <td>[(neg, bhi, microalb), (bhi, microalb, urn), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Monica Latte</td>\n",
       "      <td>[WeServeEveryone Clinic\\t \\n, 1111 First Stree...</td>\n",
       "      <td>[weserveeveryon, clinic, first, street, califo...</td>\n",
       "      <td>[lisinopril, auscult, report, glucos, microalb...</td>\n",
       "      <td>[(lisinopril, auscult), (auscult, report), (re...</td>\n",
       "      <td>[(lisinopril, auscult, report), (auscult, repo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Steve Apple</td>\n",
       "      <td>[Use for April 2011 abstraction\\n, \\n, WeServe...</td>\n",
       "      <td>[use, april, abstract, weserveeveryon, clinic,...</td>\n",
       "      <td>[flowsheet, lisinopril, marri, neg, steve, per...</td>\n",
       "      <td>[(flowsheet, lisinopril), (lisinopril, marri),...</td>\n",
       "      <td>[(flowsheet, lisinopril, marri), (lisinopril, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tom Gellato</td>\n",
       "      <td>[Use for January 2011 abstraction\\n, \\n, WeSer...</td>\n",
       "      <td>[use, januari, abstract, weserveeveryon, clini...</td>\n",
       "      <td>[neg, tom, microalb, urn, race, social, monito...</td>\n",
       "      <td>[(neg, tom), (night, ago), (white, lower), (op...</td>\n",
       "      <td>[(neg, tom, microalb), (tom, microalb, urn), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wendy See</td>\n",
       "      <td>[Use for October 2010 abstraction \\n, \\n, WeSe...</td>\n",
       "      <td>[use, octob, abstract, weserveeveryon, clinic,...</td>\n",
       "      <td>[social, cap, report, millennium, health, lowe...</td>\n",
       "      <td>[(social, cap), (cap, report), (report, millen...</td>\n",
       "      <td>[(social, cap, report), (cap, report, millenni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          names                                           document  \\\n",
       "0      Adam Pie  [Use for January 2011 abstraction\\n, \\n, WeSer...   \n",
       "1  Bill Windows  [Use for April 2011 abstraction \\n, \\n, WeServ...   \n",
       "2    Billy Gato  [Use for October 2010 abstraction\\n, \\n, WeSer...   \n",
       "3  Cherie Amore  [Use for October 2010 abstraction\\n, \\n, WeSer...   \n",
       "4    John Donut  [WeServeEveryone Clinic\\t \\n, 1111 First Stree...   \n",
       "5  Monica Latte  [WeServeEveryone Clinic\\t \\n, 1111 First Stree...   \n",
       "6   Steve Apple  [Use for April 2011 abstraction\\n, \\n, WeServe...   \n",
       "7   Tom Gellato  [Use for January 2011 abstraction\\n, \\n, WeSer...   \n",
       "8     Wendy See  [Use for October 2010 abstraction \\n, \\n, WeSe...   \n",
       "\n",
       "                                   modified_document  \\\n",
       "0  [use, januari, abstract, weserveeveryon, clini...   \n",
       "1  [use, april, abstract, weserveeveryon, clinic,...   \n",
       "2  [use, octob, abstract, weserveeveryon, clinic,...   \n",
       "3  [use, octob, abstract, weserveeveryon, clinic,...   \n",
       "4  [weserveeveryon, clinic, first, street, califo...   \n",
       "5  [weserveeveryon, clinic, first, street, califo...   \n",
       "6  [use, april, abstract, weserveeveryon, clinic,...   \n",
       "7  [use, januari, abstract, weserveeveryon, clini...   \n",
       "8  [use, octob, abstract, weserveeveryon, clinic,...   \n",
       "\n",
       "                           Document_except_rare_freq  \\\n",
       "0  [neg, bhi, microalb, urn, race, lab, social, m...   \n",
       "1  [flowsheet, night, hypoglycem, account, bill, ...   \n",
       "2  [neg, lab, race, social, monitor, report, acco...   \n",
       "3  [social, account, millennium, glucos, consult,...   \n",
       "4  [neg, bhi, microalb, urn, lab, race, monitor, ...   \n",
       "5  [lisinopril, auscult, report, glucos, microalb...   \n",
       "6  [flowsheet, lisinopril, marri, neg, steve, per...   \n",
       "7  [neg, tom, microalb, urn, race, social, monito...   \n",
       "8  [social, cap, report, millennium, health, lowe...   \n",
       "\n",
       "                                             bigrams  \\\n",
       "0  [(neg, bhi), (bhi, microalb), (microalb, urn),...   \n",
       "1  [(flowsheet, night), (night, hypoglycem), (hyp...   \n",
       "2  [(neg, lab), (ago, year), (ophthalmolog, lower...   \n",
       "3  [(social, account), (account, millennium), (mi...   \n",
       "4  [(neg, bhi), (lisinopril, better), (ophthalmol...   \n",
       "5  [(lisinopril, auscult), (auscult, report), (re...   \n",
       "6  [(flowsheet, lisinopril), (lisinopril, marri),...   \n",
       "7  [(neg, tom), (night, ago), (white, lower), (op...   \n",
       "8  [(social, cap), (cap, report), (report, millen...   \n",
       "\n",
       "                                            trigrams  \n",
       "0  [(neg, bhi, microalb), (bhi, microalb, urn), (...  \n",
       "1  [(flowsheet, night, hypoglycem), (night, hypog...  \n",
       "2  [(neg, lab, race), (lab, race, social), (percu...  \n",
       "3  [(social, account, millennium), (account, mill...  \n",
       "4  [(neg, bhi, microalb), (bhi, microalb, urn), (...  \n",
       "5  [(lisinopril, auscult, report), (auscult, repo...  \n",
       "6  [(flowsheet, lisinopril, marri), (lisinopril, ...  \n",
       "7  [(neg, tom, microalb), (tom, microalb, urn), (...  \n",
       "8  [(social, cap, report), (cap, report, millenni...  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'neg': 1, 'bhi': 1, 'microalb': 1, 'urn': 1, 'race': 1, 'lab': 1, 'social': 1, 'monitor': 1, 'report': 1, 'account': 1, ...})"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.FreqDist(data_frame['Document_except_rare_freq'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame['term_frequency'] = data_frame['Document_except_rare_freq'].apply(lambda x: nltk.FreqDist(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'neg': 1, 'bhi': 1, 'microalb': 1, 'urn': 1, 'race': 1, 'lab': 1, 'social': 1, 'monitor': 1, 'report': 1, 'account': 1, ...})"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.term_frequency[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer.fit(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = tfidf_vectorizer.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.29655668, 7.51970023, 5.83794166, 7.65323163, 7.4019172 ,\n",
       "       7.29655668, 7.29655668, 7.65323163, 7.29655668, 7.29655668,\n",
       "       7.29655668, 7.29655668, 7.8073823 , 8.50052949, 7.4019172 ,\n",
       "       7.29655668, 7.29655668, 7.29655668, 8.90599459, 8.90599459,\n",
       "       7.29655668, 8.90599459, 7.29655668, 7.29655668, 7.29655668,\n",
       "       7.98970386, 8.90599459, 8.50052949, 8.90599459, 7.51970023,\n",
       "       7.4019172 , 7.65323163, 8.21284741, 8.90599459, 7.29655668,\n",
       "       7.29655668, 8.50052949, 7.98970386, 7.8073823 , 6.70877002,\n",
       "       7.65323163, 7.4019172 , 7.8073823 , 7.8073823 , 7.29655668,\n",
       "       8.50052949, 7.29655668, 6.82655305, 6.65470279, 8.90599459,\n",
       "       7.29655668, 5.86147216, 6.16515457, 7.29655668, 7.29655668,\n",
       "       7.51970023, 7.4019172 , 7.29655668, 7.4019172 , 5.83794166,\n",
       "       8.21284741, 7.4019172 , 7.65323163, 6.65470279, 6.42108794,\n",
       "       5.86147216, 6.26693726, 5.77050038, 8.50052949, 7.29655668,\n",
       "       7.29655668, 7.29655668, 7.4019172 , 8.90599459, 5.93558013,\n",
       "       8.50052949, 6.10263421, 6.16515457, 6.38026595, 7.51970023,\n",
       "       7.4019172 , 8.50052949, 8.90599459, 7.29655668, 6.70877002,\n",
       "       6.16515457, 6.30330491, 7.4019172 , 8.50052949, 7.29655668,\n",
       "       7.29655668, 7.29655668, 7.8073823 , 7.29655668, 7.4019172 ,\n",
       "       7.29655668, 7.29655668, 8.90599459, 7.11423512, 7.29655668,\n",
       "       7.29655668, 7.51970023, 6.65470279, 7.29655668, 7.29655668,\n",
       "       4.68648689, 7.03419242, 7.4019172 , 8.50052949, 6.10263421,\n",
       "       7.29655668, 7.29655668, 6.89109157, 8.21284741, 6.96008444,\n",
       "       7.29655668, 7.03419242, 7.29655668, 7.29655668, 5.98822386,\n",
       "       7.29655668, 7.29655668, 7.29655668, 7.29655668, 8.50052949,\n",
       "       6.16515457, 7.65323163, 8.90599459, 8.50052949, 7.29655668,\n",
       "       7.29655668, 6.65470279, 7.29655668, 6.65470279, 7.29655668,\n",
       "       7.29655668, 6.76592843, 7.29655668, 7.29655668, 7.29655668,\n",
       "       7.29655668, 7.29655668, 7.29655668, 8.90599459, 7.51970023,\n",
       "       7.8073823 , 7.98970386, 5.81495214, 7.11423512, 7.29655668,\n",
       "       7.98970386, 6.26693726, 8.50052949, 8.50052949, 7.29655668,\n",
       "       5.77050038, 7.65323163, 8.21284741, 6.65470279, 5.98822386,\n",
       "       8.90599459, 7.65323163, 6.6034095 , 8.50052949, 6.82655305,\n",
       "       7.29655668, 8.50052949, 6.23184594, 7.29655668, 7.29655668,\n",
       "       7.29655668, 7.51970023, 7.51970023, 8.90599459, 8.21284741,\n",
       "       7.51970023, 7.29655668, 7.98970386, 8.90599459, 7.98970386,\n",
       "       8.90599459, 7.29655668, 6.65470279, 7.29655668, 7.29655668,\n",
       "       7.65323163, 7.4019172 , 8.90599459, 8.50052949, 7.29655668,\n",
       "       7.51970023, 7.29655668, 6.65470279, 8.21284741, 6.65470279,\n",
       "       7.8073823 , 7.29655668, 7.29655668, 7.29655668, 7.29655668,\n",
       "       7.2012465 , 8.21284741, 7.29655668, 6.65470279, 7.4019172 ,\n",
       "       6.65470279, 8.90599459, 6.10263421, 7.29655668, 6.07278125,\n",
       "       7.29655668, 7.29655668, 6.65470279, 8.90599459, 7.29655668,\n",
       "       8.90599459, 7.98970386, 7.8073823 , 8.21284741, 6.55461934,\n",
       "       8.90599459, 6.65470279, 7.29655668, 7.29655668, 7.29655668,\n",
       "       7.29655668, 6.10263421, 7.29655668, 7.29655668, 7.51970023,\n",
       "       7.29655668, 6.65470279, 7.29655668, 7.4019172 , 6.82655305,\n",
       "       8.90599459, 7.29655668, 8.21284741, 7.29655668, 7.29655668,\n",
       "       7.29655668, 7.4019172 , 8.50052949, 7.8073823 , 6.26693726,\n",
       "       7.65323163, 7.29655668, 8.90599459, 6.70877002, 8.90599459,\n",
       "       8.90599459, 6.70877002, 8.90599459, 7.4019172 , 6.65470279,\n",
       "       6.70877002, 7.29655668, 7.29655668, 7.29655668, 6.76592843,\n",
       "       7.8073823 , 7.4019172 , 6.89109157, 8.90599459, 7.29655668,\n",
       "       7.65323163, 7.29655668, 7.29655668, 6.30330491, 7.98970386,\n",
       "       7.29655668, 7.29655668, 8.21284741, 8.50052949, 7.8073823 ,\n",
       "       8.50052949, 6.13340587, 7.03419242, 6.42108794, 8.90599459,\n",
       "       7.29655668, 7.29655668, 6.50809932, 6.76592843, 8.90599459,\n",
       "       4.88961157, 7.8073823 , 7.8073823 , 6.65470279, 6.65470279,\n",
       "       6.50809932, 7.65323163, 6.65470279, 6.10263421, 8.50052949,\n",
       "       7.65323163, 7.11423512, 8.90599459, 7.29655668, 6.65470279,\n",
       "       8.50052949, 7.51970023, 7.29655668, 7.29655668, 7.29655668,\n",
       "       7.29655668, 7.29655668, 7.65323163, 7.29655668, 7.29655668,\n",
       "       7.4019172 , 7.29655668, 7.8073823 , 7.29655668, 6.34104524,\n",
       "       7.29655668, 7.4019172 , 7.29655668, 8.21284741, 6.38026595,\n",
       "       8.90599459, 7.8073823 , 7.29655668, 6.55461934, 8.50052949,\n",
       "       7.29655668, 7.29655668, 6.26693726, 5.77050038, 6.65470279,\n",
       "       6.30330491, 8.50052949, 7.29655668, 7.29655668, 7.29655668,\n",
       "       7.29655668, 7.29655668, 8.50052949, 6.65470279, 7.65323163,\n",
       "       7.51970023, 7.51970023, 6.38026595, 8.21284741, 7.4019172 ,\n",
       "       7.29655668, 7.98970386, 8.90599459, 7.4019172 , 6.82655305,\n",
       "       6.76592843, 6.65470279, 8.50052949, 7.29655668, 6.65470279,\n",
       "       7.4019172 , 7.29655668, 7.65323163, 7.2012465 , 6.65470279,\n",
       "       7.29655668, 8.50052949, 7.29655668, 6.82655305, 7.98970386,\n",
       "       7.29655668, 6.34104524, 6.76592843, 8.50052949, 7.65323163,\n",
       "       6.70877002, 6.70877002, 6.26693726, 7.29655668, 7.29655668,\n",
       "       7.29655668, 7.29655668, 6.70877002, 7.29655668, 6.65470279,\n",
       "       7.65323163, 6.65470279, 6.26693726, 8.21284741, 7.2012465 ,\n",
       "       7.29655668, 6.89109157, 6.26693726, 7.29655668, 8.50052949,\n",
       "       7.29655668, 7.51970023, 6.04379371, 7.51970023, 7.29655668,\n",
       "       8.90599459, 8.90599459, 6.65470279, 7.29655668, 7.4019172 ,\n",
       "       8.50052949, 8.50052949, 7.29655668, 8.90599459, 8.90599459,\n",
       "       7.11423512, 7.51970023, 6.34104524, 7.29655668, 7.29655668,\n",
       "       8.50052949, 7.29655668, 7.8073823 , 7.4019172 , 7.29655668,\n",
       "       6.65470279, 6.26693726, 7.8073823 , 7.29655668, 5.98822386,\n",
       "       7.29655668, 7.29655668, 7.29655668, 7.29655668, 5.98822386,\n",
       "       6.89109157, 7.29655668, 7.51970023, 7.29655668, 6.16515457,\n",
       "       7.29655668, 6.82655305, 6.89109157, 7.2012465 , 7.29655668,\n",
       "       7.29655668, 7.29655668, 8.90599459, 6.65470279, 6.65470279,\n",
       "       6.65470279, 7.29655668, 7.8073823 , 6.34104524, 7.29655668,\n",
       "       7.29655668, 7.29655668, 7.29655668, 7.29655668, 8.50052949,\n",
       "       7.4019172 , 7.4019172 , 6.89109157, 7.4019172 , 6.82655305,\n",
       "       7.29655668, 7.4019172 , 8.50052949, 7.8073823 , 7.29655668,\n",
       "       7.51970023, 7.29655668, 7.51970023, 6.6034095 , 6.70877002,\n",
       "       5.77050038, 7.29655668, 8.90599459, 7.29655668, 7.29655668,\n",
       "       6.26693726, 6.76592843, 8.50052949, 5.68711877, 7.98970386,\n",
       "       7.29655668, 7.8073823 , 8.90599459, 8.50052949, 7.98970386,\n",
       "       8.90599459, 6.38026595, 8.50052949, 7.51970023, 7.29655668,\n",
       "       6.6034095 , 7.29655668, 7.8073823 ])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame['tfidf'] = data_frame['Document_except_rare_freq'].apply(lambda x: tfidf_vectorizer.transform(x).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>document</th>\n",
       "      <th>modified_document</th>\n",
       "      <th>Document_except_rare_freq</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "      <th>term_frequency</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adam Pie</td>\n",
       "      <td>[Use for January 2011 abstraction\\n, \\n, WeSer...</td>\n",
       "      <td>[use, januari, abstract, weserveeveryon, clini...</td>\n",
       "      <td>[neg, bhi, microalb, urn, race, lab, social, m...</td>\n",
       "      <td>[(neg, bhi), (bhi, microalb), (microalb, urn),...</td>\n",
       "      <td>[(neg, bhi, microalb), (bhi, microalb, urn), (...</td>\n",
       "      <td>{'neg': 1, 'bhi': 1, 'microalb': 1, 'urn': 1, ...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bill Windows</td>\n",
       "      <td>[Use for April 2011 abstraction \\n, \\n, WeServ...</td>\n",
       "      <td>[use, april, abstract, weserveeveryon, clinic,...</td>\n",
       "      <td>[flowsheet, night, hypoglycem, account, bill, ...</td>\n",
       "      <td>[(flowsheet, night), (night, hypoglycem), (hyp...</td>\n",
       "      <td>[(flowsheet, night, hypoglycem), (night, hypog...</td>\n",
       "      <td>{'flowsheet': 1, 'night': 1, 'hypoglycem': 1, ...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Billy Gato</td>\n",
       "      <td>[Use for October 2010 abstraction\\n, \\n, WeSer...</td>\n",
       "      <td>[use, octob, abstract, weserveeveryon, clinic,...</td>\n",
       "      <td>[neg, lab, race, social, monitor, report, acco...</td>\n",
       "      <td>[(neg, lab), (ago, year), (ophthalmolog, lower...</td>\n",
       "      <td>[(neg, lab, race), (lab, race, social), (percu...</td>\n",
       "      <td>{'neg': 1, 'lab': 1, 'race': 1, 'social': 1, '...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cherie Amore</td>\n",
       "      <td>[Use for October 2010 abstraction\\n, \\n, WeSer...</td>\n",
       "      <td>[use, octob, abstract, weserveeveryon, clinic,...</td>\n",
       "      <td>[social, account, millennium, glucos, consult,...</td>\n",
       "      <td>[(social, account), (account, millennium), (mi...</td>\n",
       "      <td>[(social, account, millennium), (account, mill...</td>\n",
       "      <td>{'social': 1, 'account': 1, 'millennium': 1, '...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John Donut</td>\n",
       "      <td>[WeServeEveryone Clinic\\t \\n, 1111 First Stree...</td>\n",
       "      <td>[weserveeveryon, clinic, first, street, califo...</td>\n",
       "      <td>[neg, bhi, microalb, urn, lab, race, monitor, ...</td>\n",
       "      <td>[(neg, bhi), (lisinopril, better), (ophthalmol...</td>\n",
       "      <td>[(neg, bhi, microalb), (bhi, microalb, urn), (...</td>\n",
       "      <td>{'neg': 1, 'bhi': 1, 'microalb': 1, 'urn': 1, ...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Monica Latte</td>\n",
       "      <td>[WeServeEveryone Clinic\\t \\n, 1111 First Stree...</td>\n",
       "      <td>[weserveeveryon, clinic, first, street, califo...</td>\n",
       "      <td>[lisinopril, auscult, report, glucos, microalb...</td>\n",
       "      <td>[(lisinopril, auscult), (auscult, report), (re...</td>\n",
       "      <td>[(lisinopril, auscult, report), (auscult, repo...</td>\n",
       "      <td>{'lisinopril': 1, 'auscult': 1, 'report': 1, '...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Steve Apple</td>\n",
       "      <td>[Use for April 2011 abstraction\\n, \\n, WeServe...</td>\n",
       "      <td>[use, april, abstract, weserveeveryon, clinic,...</td>\n",
       "      <td>[flowsheet, lisinopril, marri, neg, steve, per...</td>\n",
       "      <td>[(flowsheet, lisinopril), (lisinopril, marri),...</td>\n",
       "      <td>[(flowsheet, lisinopril, marri), (lisinopril, ...</td>\n",
       "      <td>{'flowsheet': 1, 'lisinopril': 1, 'marri': 1, ...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tom Gellato</td>\n",
       "      <td>[Use for January 2011 abstraction\\n, \\n, WeSer...</td>\n",
       "      <td>[use, januari, abstract, weserveeveryon, clini...</td>\n",
       "      <td>[neg, tom, microalb, urn, race, social, monito...</td>\n",
       "      <td>[(neg, tom), (night, ago), (white, lower), (op...</td>\n",
       "      <td>[(neg, tom, microalb), (tom, microalb, urn), (...</td>\n",
       "      <td>{'neg': 1, 'tom': 1, 'microalb': 1, 'urn': 1, ...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wendy See</td>\n",
       "      <td>[Use for October 2010 abstraction \\n, \\n, WeSe...</td>\n",
       "      <td>[use, octob, abstract, weserveeveryon, clinic,...</td>\n",
       "      <td>[social, cap, report, millennium, health, lowe...</td>\n",
       "      <td>[(social, cap), (cap, report), (report, millen...</td>\n",
       "      <td>[(social, cap, report), (cap, report, millenni...</td>\n",
       "      <td>{'social': 1, 'cap': 1, 'report': 1, 'millenni...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          names                                           document  \\\n",
       "0      Adam Pie  [Use for January 2011 abstraction\\n, \\n, WeSer...   \n",
       "1  Bill Windows  [Use for April 2011 abstraction \\n, \\n, WeServ...   \n",
       "2    Billy Gato  [Use for October 2010 abstraction\\n, \\n, WeSer...   \n",
       "3  Cherie Amore  [Use for October 2010 abstraction\\n, \\n, WeSer...   \n",
       "4    John Donut  [WeServeEveryone Clinic\\t \\n, 1111 First Stree...   \n",
       "5  Monica Latte  [WeServeEveryone Clinic\\t \\n, 1111 First Stree...   \n",
       "6   Steve Apple  [Use for April 2011 abstraction\\n, \\n, WeServe...   \n",
       "7   Tom Gellato  [Use for January 2011 abstraction\\n, \\n, WeSer...   \n",
       "8     Wendy See  [Use for October 2010 abstraction \\n, \\n, WeSe...   \n",
       "\n",
       "                                   modified_document  \\\n",
       "0  [use, januari, abstract, weserveeveryon, clini...   \n",
       "1  [use, april, abstract, weserveeveryon, clinic,...   \n",
       "2  [use, octob, abstract, weserveeveryon, clinic,...   \n",
       "3  [use, octob, abstract, weserveeveryon, clinic,...   \n",
       "4  [weserveeveryon, clinic, first, street, califo...   \n",
       "5  [weserveeveryon, clinic, first, street, califo...   \n",
       "6  [use, april, abstract, weserveeveryon, clinic,...   \n",
       "7  [use, januari, abstract, weserveeveryon, clini...   \n",
       "8  [use, octob, abstract, weserveeveryon, clinic,...   \n",
       "\n",
       "                           Document_except_rare_freq  \\\n",
       "0  [neg, bhi, microalb, urn, race, lab, social, m...   \n",
       "1  [flowsheet, night, hypoglycem, account, bill, ...   \n",
       "2  [neg, lab, race, social, monitor, report, acco...   \n",
       "3  [social, account, millennium, glucos, consult,...   \n",
       "4  [neg, bhi, microalb, urn, lab, race, monitor, ...   \n",
       "5  [lisinopril, auscult, report, glucos, microalb...   \n",
       "6  [flowsheet, lisinopril, marri, neg, steve, per...   \n",
       "7  [neg, tom, microalb, urn, race, social, monito...   \n",
       "8  [social, cap, report, millennium, health, lowe...   \n",
       "\n",
       "                                             bigrams  \\\n",
       "0  [(neg, bhi), (bhi, microalb), (microalb, urn),...   \n",
       "1  [(flowsheet, night), (night, hypoglycem), (hyp...   \n",
       "2  [(neg, lab), (ago, year), (ophthalmolog, lower...   \n",
       "3  [(social, account), (account, millennium), (mi...   \n",
       "4  [(neg, bhi), (lisinopril, better), (ophthalmol...   \n",
       "5  [(lisinopril, auscult), (auscult, report), (re...   \n",
       "6  [(flowsheet, lisinopril), (lisinopril, marri),...   \n",
       "7  [(neg, tom), (night, ago), (white, lower), (op...   \n",
       "8  [(social, cap), (cap, report), (report, millen...   \n",
       "\n",
       "                                            trigrams  \\\n",
       "0  [(neg, bhi, microalb), (bhi, microalb, urn), (...   \n",
       "1  [(flowsheet, night, hypoglycem), (night, hypog...   \n",
       "2  [(neg, lab, race), (lab, race, social), (percu...   \n",
       "3  [(social, account, millennium), (account, mill...   \n",
       "4  [(neg, bhi, microalb), (bhi, microalb, urn), (...   \n",
       "5  [(lisinopril, auscult, report), (auscult, repo...   \n",
       "6  [(flowsheet, lisinopril, marri), (lisinopril, ...   \n",
       "7  [(neg, tom, microalb), (tom, microalb, urn), (...   \n",
       "8  [(social, cap, report), (cap, report, millenni...   \n",
       "\n",
       "                                      term_frequency  \\\n",
       "0  {'neg': 1, 'bhi': 1, 'microalb': 1, 'urn': 1, ...   \n",
       "1  {'flowsheet': 1, 'night': 1, 'hypoglycem': 1, ...   \n",
       "2  {'neg': 1, 'lab': 1, 'race': 1, 'social': 1, '...   \n",
       "3  {'social': 1, 'account': 1, 'millennium': 1, '...   \n",
       "4  {'neg': 1, 'bhi': 1, 'microalb': 1, 'urn': 1, ...   \n",
       "5  {'lisinopril': 1, 'auscult': 1, 'report': 1, '...   \n",
       "6  {'flowsheet': 1, 'lisinopril': 1, 'marri': 1, ...   \n",
       "7  {'neg': 1, 'tom': 1, 'microalb': 1, 'urn': 1, ...   \n",
       "8  {'social': 1, 'cap': 1, 'report': 1, 'millenni...   \n",
       "\n",
       "                                               tfidf  \n",
       "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "3  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "4  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "5  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "6  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "7  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "8  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autocorrect import Speller\n",
    "spellchk = Speller(threshold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spellchecker'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-e2e45e4f9ba1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mspellchecker\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSpellChecker\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spellchecker'"
     ]
    }
   ],
   "source": [
    "from spellchecker import SpellChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spellchecker\n",
      "  Downloading https://files.pythonhosted.org/packages/8d/2f/95ff55a821f6fc83999f8418045ee472edcfd5fb06905090f68fda56a82a/spellchecker-0.4.tar.gz (3.9MB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lokesh\\anaconda3\\lib\\site-packages (from spellchecker) (41.0.1)\n",
      "Collecting inexactsearch (from spellchecker)\n",
      "  Downloading https://files.pythonhosted.org/packages/45/23/0b398af4295da99c5ab69d7b0bff36a2cb68e260a65f64717c17f6a20035/inexactsearch-1.0.2.tar.gz\n",
      "Collecting soundex>=1.0 (from inexactsearch->spellchecker)\n",
      "  Downloading https://files.pythonhosted.org/packages/f8/8f/37b9711595d007e82f70ae6f41b6ab6a1fda406a8321ccfc458fb5023b5f/soundex-1.1.3.tar.gz\n",
      "Collecting silpa_common>=0.3 (from inexactsearch->spellchecker)\n",
      "  Downloading https://files.pythonhosted.org/packages/8d/55/452f5103cb7071d188a818d9e2f12c19c4c8a12124a28aaa212eb6716a4d/silpa_common-0.3.tar.gz\n",
      "Building wheels for collected packages: spellchecker, inexactsearch, soundex, silpa-common\n",
      "  Running setup.py bdist_wheel for spellchecker: started\n",
      "  Running setup.py bdist_wheel for spellchecker: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\lokesh\\AppData\\Local\\pip\\Cache\\wheels\\a2\\e6\\ad\\28ab959cba7100f5c562a3d1711cd34b630734d241c4e1bd40\n",
      "  Running setup.py bdist_wheel for inexactsearch: started\n",
      "  Running setup.py bdist_wheel for inexactsearch: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\lokesh\\AppData\\Local\\pip\\Cache\\wheels\\58\\e0\\c1\\e3fed0e9fd1a3708bc91870fb0ba30ef88527540006763674b\n",
      "  Running setup.py bdist_wheel for soundex: started\n",
      "  Running setup.py bdist_wheel for soundex: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\lokesh\\AppData\\Local\\pip\\Cache\\wheels\\b5\\bb\\e6\\9a4b6be56c40aa707509bddaf6d414187461ded9db7a25a41a\n",
      "  Running setup.py bdist_wheel for silpa-common: started\n",
      "  Running setup.py bdist_wheel for silpa-common: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\lokesh\\AppData\\Local\\pip\\Cache\\wheels\\16\\4f\\ba\\604a82bf904740f1a1d3ad88029c0df5c638bd8825a3cb972d\n",
      "Successfully built spellchecker inexactsearch soundex silpa-common\n",
      "Installing collected packages: silpa-common, soundex, inexactsearch, spellchecker\n",
      "Successfully installed inexactsearch-1.0.2 silpa-common-0.3 soundex-1.1.3 spellchecker-0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "thinc 6.10.3 requires msgpack<1.0.0,>=0.5.6, which is not installed.\n",
      "msgpack-numpy 0.4.4.3 requires msgpack>=0.5.2, which is not installed.\n",
      "distributed 1.21.8 requires msgpack, which is not installed.\n",
      "tensorflow 1.10.0 has requirement numpy<=1.14.5,>=1.13.3, but you'll have numpy 1.17.0 which is incompatible.\n",
      "tensorflow 1.10.0 has requirement setuptools<=39.1.0, but you'll have setuptools 41.0.1 which is incompatible.\n",
      "tensorflow 1.10.0 has requirement tensorboard<1.11.0,>=1.10.0, but you'll have tensorboard 1.14.0 which is incompatible.\n",
      "spacy 2.0.13 has requirement msgpack-numpy<0.29,<0.4.4.0murmurhash>=0.28, but you'll have msgpack-numpy 0.4.4.3 which is incompatible.\n",
      "spacy 2.0.13 has requirement regex==2018.01.10, but you'll have regex 2017.11.9 which is incompatible.\n",
      "cufflinks 0.16 has requirement plotly<4.0.0a0,>=3.0.0, but you'll have plotly 4.1.0 which is incompatible.\n",
      "You are using pip version 10.0.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install spellchecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tiger'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spellchk('tigrr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame['spell_corrected_doc'] = data_frame['modified_document'].apply(lambda x: [spellchk(word) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "717"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_frame['spell_corrected_doc'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp1  = data_frame['spell_corrected_doc'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2  = data_frame['modified_document'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp1 == temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_df = pd.DataFrame({'wrong':temp2,'right':temp1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wrong</th>\n",
       "      <th>right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>januari</td>\n",
       "      <td>january</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>summari</td>\n",
       "      <td>summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>commerci</td>\n",
       "      <td>commerce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>xxxxx</td>\n",
       "      <td>xxxix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>piehom</td>\n",
       "      <td>pigdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>activ</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>malemarit</td>\n",
       "      <td>malemuit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>languag</td>\n",
       "      <td>language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>byemp</td>\n",
       "      <td>hemp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>fulltim</td>\n",
       "      <td>fulltime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>emailsen</td>\n",
       "      <td>mailmen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>diabet</td>\n",
       "      <td>diabeta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>icd</td>\n",
       "      <td>ice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>hypertens</td>\n",
       "      <td>hypertense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>essenti</td>\n",
       "      <td>essentia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>icd</td>\n",
       "      <td>ice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>icd</td>\n",
       "      <td>ice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>retinopathi</td>\n",
       "      <td>retinopathy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>diabet</td>\n",
       "      <td>diabeta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>icd</td>\n",
       "      <td>ice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>polyneuropathi</td>\n",
       "      <td>polyneuropathy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>diabet</td>\n",
       "      <td>diabeta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>icd</td>\n",
       "      <td>ice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>hytrin</td>\n",
       "      <td>hygrin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>terazosin</td>\n",
       "      <td>prazosin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>qd</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>refil</td>\n",
       "      <td>refill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>savem</td>\n",
       "      <td>save</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>qd</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>refil</td>\n",
       "      <td>refill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>mmoll</td>\n",
       "      <td>moll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>mgdl</td>\n",
       "      <td>mgal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>mgdl</td>\n",
       "      <td>mgal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>mmoll</td>\n",
       "      <td>moll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>sgot</td>\n",
       "      <td>got</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>ul</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>bili</td>\n",
       "      <td>bill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>mgdl</td>\n",
       "      <td>mgal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>mgdl</td>\n",
       "      <td>mgal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>ldh</td>\n",
       "      <td>lh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>iul</td>\n",
       "      <td>ill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>mmoll</td>\n",
       "      <td>moll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>hbac</td>\n",
       "      <td>abac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>hbac</td>\n",
       "      <td>abac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>profil</td>\n",
       "      <td>profit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>mgdl</td>\n",
       "      <td>mgal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>triglycerid</td>\n",
       "      <td>triglyceride</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>mgdl</td>\n",
       "      <td>mgal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>summari</td>\n",
       "      <td>summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>commerci</td>\n",
       "      <td>commerce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>temperatur</td>\n",
       "      <td>temperature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>siteor</td>\n",
       "      <td>sister</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>systol</td>\n",
       "      <td>systole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>diastol</td>\n",
       "      <td>diastole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>mgdl</td>\n",
       "      <td>mgal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>mgdl</td>\n",
       "      <td>mgal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>mgdl</td>\n",
       "      <td>mgal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>mgdl</td>\n",
       "      <td>mgal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>cxr</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>td</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              wrong           right\n",
       "1           januari         january\n",
       "10          summari         summary\n",
       "17         commerci        commerce\n",
       "18            xxxxx           xxxix\n",
       "23           piehom          pigdom\n",
       "39            activ          active\n",
       "41        malemarit        malemuit\n",
       "50          languag        language\n",
       "58            byemp            hemp\n",
       "60          fulltim        fulltime\n",
       "61         emailsen         mailmen\n",
       "70           diabet         diabeta\n",
       "72              icd             ice\n",
       "73        hypertens      hypertense\n",
       "75          essenti        essentia\n",
       "76              icd             ice\n",
       "78              icd             ice\n",
       "79      retinopathi     retinopathy\n",
       "80           diabet         diabeta\n",
       "81              icd             ice\n",
       "82   polyneuropathi  polyneuropathy\n",
       "83           diabet         diabeta\n",
       "84              icd             ice\n",
       "86           hytrin          hygrin\n",
       "89        terazosin        prazosin\n",
       "92               qd               d\n",
       "94            refil          refill\n",
       "96            savem            save\n",
       "102              qd               d\n",
       "104           refil          refill\n",
       "..              ...             ...\n",
       "610           mmoll            moll\n",
       "612            mgdl            mgal\n",
       "614            mgdl            mgal\n",
       "616           mmoll            moll\n",
       "617            sgot             got\n",
       "619              ul              up\n",
       "620            bili            bill\n",
       "622            mgdl            mgal\n",
       "625            mgdl            mgal\n",
       "626             ldh              lh\n",
       "628             iul             ill\n",
       "630           mmoll            moll\n",
       "631            hbac            abac\n",
       "633            hbac            abac\n",
       "636          profil          profit\n",
       "639            mgdl            mgal\n",
       "640     triglycerid    triglyceride\n",
       "641            mgdl            mgal\n",
       "654         summari         summary\n",
       "660        commerci        commerce\n",
       "667      temperatur     temperature\n",
       "670          siteor          sister\n",
       "680          systol         systole\n",
       "684         diastol        diastole\n",
       "688            mgdl            mgal\n",
       "690            mgdl            mgal\n",
       "692            mgdl            mgal\n",
       "695            mgdl            mgal\n",
       "696             cxr             car\n",
       "710              td              to\n",
       "\n",
       "[197 rows x 2 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrected_df[corrected_df['wrong'] != corrected_df['right']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "strtemp = ' '.join(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Patient ID: 0000-88888\\t']"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('Patient ID: .+\\\\t|Patient ID: .+\\\\n',strtemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Birth Date: 08/08/1948\\t']"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('Birth Date: .+\\\\t|Birth Date: .+\\\\n',strtemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gender: Male\\t']"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('Gender: .+\\\\t|Gender: .+\\\\n',strtemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Marital Status: Married\\n']"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('Marital Status: .+\\\\t|Marital Status: .+\\\\n',strtemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Race: White\\n']"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('Race: .+\\\\t|Race: .+\\\\n',strtemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Language: English\\n']"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('Language: .+\\\\t|Language: .+\\\\n',strtemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Resp Prov: Carl Savem\\t']"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('Resp Prov: .+\\\\t|Resp Prov: .+\\\\n',strtemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MRN: MR-111-1111\\n']"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('MRN: .+\\\\t|MRN: .+\\\\n',strtemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Emp. Status: Full-time\\n']"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('Emp. Status: .+\\\\t|Emp. Status: .+\\\\n',strtemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['External ID: MR-111-1111\\n']"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('External ID: .+\\\\t|External ID: .+\\\\n',strtemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Problems\\n DIABETES MELLITUS (ICD-250.)']"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('Problems\\\\n\\s.+',strtemp,re.MULTILINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Use for January 2011 abstraction\\n \\n WeServeEveryone Clinic\\t \\n 1111 First Street California\\n 111-111-11111   Fax: 111-111-1111\\tChart Summary\\n Adam Pie\\n \\n Home: 888-888-8888\\n Male   DOB: 08/08/1948\\t0000-88888\\tIns: Commercial xxxxx\\n                                                      \\n \\n Patient Information\\n Name: Adam Pie\\tHome Phone: 888-888-8888\\n Address: 1111 Donut Road\\n                 Fast Food, California  \\tOffice Phone:\\n Patient ID: 0000-88888\\tFax:\\n Birth Date: 08/08/1948\\tStatus: Active\\n Gender: Male\\tMarital Status: Married\\n Contact By: Phone \\tRace: White\\n Soc Sec No: 111-11-1111\\tLanguage: English\\n Resp Prov: Carl Savem\\tMRN: MR-111-1111\\n Referred by:\\tEmp. Status: Full-time\\n Email:\\tSens Chart: No\\n Home LOC: WeServeEveryone \\tExternal ID: MR-111-1111\\n Problems\\n DIABETES MELLITUS (ICD-250.)\\n HYPERTENSION, BENIGN ESSENTIAL (ICD-401.1)\\n DEPRESSION (ICD-311)\\n RETINOPATHY, DIABETIC (ICD-362.0)\\n POLYNEUROPATHY IN DIABETES (ICD-357.2)\\n \\n Medications\\n HYTRIN CAP 5MG (TERAZOSIN HCL) 1 po qd\\n Last Refill: #30 x 0 : Carl Savem (10/27/2010)\\n PRINIVIL TABS 20 MG (LISINOPRIL) 1 po qd\\n Last Refill: #30 x 2 : Carl Savem MD (10/27/2010)\\n HUMULIN INJ 70/30 (INSULIN REG & ISOPHANE (HUMAN)) 20 units ac breakfast\\n Last Refill: #600 u x 0 : Carl Savem MD (10/27/2010)\\n PROZAC CAPS 10 MG (FLUOXETINE HCL) 1 po qd\\n Last Refill: #30 x 2 : Carl Savem MD (10/27/2010)\\n \\n Directives\\n DO NOT RESUSCITATE\\n \\n Allergies and Adverse Reactions (! = critical)\\n \\n ! CODEINE\\n \\n Services Due\\n \\n HEMOCCULT or SIGMOID, BP DIASTOLIC, BP SYSTOLIC, FLU VAX, PNEUMOVAX, MICROALB URN, FLU VAX, BP DIASTOLIC, BP SYSTOLIC, FUNDUSCOPY, DIAB FOOT CK, ALBUMIN URIN, TSH, CHOLESTEROL, HGBA1C, CREATININE.\\n \\n 12/18/2010 - Office Visit: F/u Diabetes\\n Provider: Carl Savem MD\\n Location of Care: WeServeEveryone Clinic\\n \\n OFFICE VISIT\\n \\n History of Present Illness \\n Reason for visit: Routine follow up to review medications Chief Complaint: No complaints\\n \\n History\\n Social History: His wife Marzipan died 5 years ago this month and he is more introspective.\\n \\n Diabetes Management \\n Hyperglycemic Symptoms \\n Polyuria: no\\n Polydipsia: no\\n Blurred vision: no\\n \\n Sympathomimetic Symptoms \\n Diaphoresis: no\\n Agitation: no\\n Tremor: no\\n Palpitations: no\\n Insomnia: no\\n \\n Neuroglycopenic Symptoms \\n Confusion: no\\n Lethargy: no\\n Somnolence: no\\n Amnesia: no\\n Stupor: no\\n Seizures: no\\n \\n Review of Systems\\n General: denies fatigue, malaise, fever, weight loss\\n Eyes: denies blurring, diplopia, irritation, discharge\\n Ear/Nose/Throat: denies ear pain or discharge, nasal obstruction or discharge, sore throat\\n Cardiovascular: denies chest pain, palpitations, paroxysmal nocturnal dyspnea, orthopnea, edema Respiratory: denies coughing, wheezing, dyspnea, hemoptysis\\n Gastrointestinal: denies abdominal pain, dysphagia, nausea, vomiting, diarrhea, constipation\\n Genitourinary: denies hematuria, frequency, urgency, dysuria, discharge, impotence, incontinence\\n Musculoskeletal: denies back pain, joint swelling, joint stiffness, joint pain\\n Skin: denies rashes, itching, lumps, sores, lesions, color change\\n Neurologic: denies syncope, seizures, transient paralysis, weakness, paresthesias\\n Psychiatric: denies depression, anxiety, mental disturbance, difficulty sleeping, suicidal ideation, hallucinations, paranoia\\n Endocrine: denies polyuria, polydipsia, polyphagia, weight change, heat or cold intolerance\\n Heme/Lymphatic: denies easy or excessive bruising, history of blood transfusions, anemia, bleeding disorders, adenopathy, chills, sweats\\n Allergic/Immunologic: denies urticaria, hay fever, frequent UTIs; denies HIV high risk behaviors\\n \\n Vital Signs\\n WeServeEveryone Clinic\\tMarch 24, 2011\\n 1111 First Street California\\n 111-111-11111   Fax: 111-111-1111\\tPage 2\\n Chart Summary\\n Adam Pie\\t \\n Male   DOB: 08/08/1948\\n 0000-88888\\n Ins: Commercial xxxxx\\tHome: 888-888-8888\\n Ht: 70  in.  Wt: 190  lbs.   T: 98.0 degF. T site: oral  P: 70   Rhythm: regular R: 16 BP: 158/90\\n \\n Physical Exam\\n General Appearance: well developed, well nourished, no acute distress\\n Eyes: conjunctiva and lids normal, PERRLA, EOMI, fundi WNL\\n Ears, Nose, Mouth, Throat: TM clear, nares clear, oral exam WNL\\n Respiratory: clear to auscultation and percussion, respiratory effort normal\\n Cardiovascular: regular rate and rhythm, S1-S2, no murmur, rub or gallop, no bruits, peripheral pulses normal and symmetric, no cyanosis, clubbing, edema or varicosities\\n Skin: clear, good turgor, color WNL, no rashes, lesions, or ulcerations\\n \\n Assessment\\n Problems (including changes): Adam is voiding better since increasing Hytrin to 5 mg/day. Blood pressure is lower. He is following his diet, by his account. He has not had any hypoglycemic episodes, no night sweats. Feet are inspected and there are no callouses, no compromised skin. No vision complaints.\\n \\n Impression: Sub optimal sugar, control with retinopathy and neuropathy, high glucometer readings.\\n He will work harder on diet. Will increase insulin by 2 units. BP and symptoms of prostatism are better.\\n \\n Home Glucose Monitoring: \\n AC breakfast 110 to 220\\n AC breakfast mean 142\\n AC dinner 100 to 250\\n AC dinner mean 120\\n \\n Plan\\n Medications: \\n HUMULIN INJ 70/30 20 u ac breakfast\\n PRINIVIL TABS 20 MG 1 qd\\n HYTRIN CAP 5MG 1 qd\\n PROZAC CAPS 10 MG 1 qd\\n \\n Treatment: Will have annual foot exam at next visit.\\n \\n Orders:\\n Ophthalmology consult\\n UA\\n HGBA1C\\n Metabolic Panel\\n Lipid Panel\\n Hemoccult\\n \\n Education/Counseling (time): 10 minutes\\n \\n Coordination of Care (time): 10 minutes\\n \\n Follow-up/Return Visit: 3 months\\n \\n Disposition: return to clinic\\n \\n WeServeEveryone Clinic\\tMarch 24, 2011\\n 1111 First Street California\\n 111-111-11111   Fax: 111-111-1111\\tPage 2\\n Chart Summary\\n Adam Pie\\t \\n Male   DOB: 08/08/1948\\n 0000-88888\\n Ins: Commercial xxxxx\\tHome: 888-888-8888\\n Ins: BHI (Futura) Grp: BHI1595\\n \\n 10/31/2010 - Lab Report: Metabolic Panel Provider: Carl Savem MD\\n Location of Care: Millennium Health System\\n \\n Tests:                                \\n \\n (1) Metabolic Panel  (ML-03CHEM)\\n \\n ALK  PHOS    \\t72  U/L       \\t35-100\\n BG  RANDOM  \\t125  mg/dl     \\t70-125\\n BUN    \\t16  mg/dl  \\t7-25\\n CALCIUM   \\t9.6  mg/dl  \\t8.2-10.2\\n CHLORIDE    \\t101  mmol/l   \\t96-109\\n CO2  \\t27  mmol/l   \\t23-29\\n CREATININE   \\t0.7  mg/dl     \\t0.6-1.2\\n PO4   \\t2.9  mg/dl \\t2.5-4.5\\n POTASSIUM   \\t4.5  mmol/l \\t3.5-5.3\\n SGOT  (AST) \\t31  U/L    \\t0-40\\n BILI  TOTAL\\t0.7  mg/dl        \\t0.0-1.3\\n URIC  ACID    \\t4.8  mg/dl     \\t3.4-7.0\\n LDH,  TOTAL      \\t136  IU/L    \\t0-200\\n SODIUM     \\t135  mmol/l      \\t135-145\\n (2) HbA1c Test\\n HbA1c level    6.0%\\n (3) Lipid Profile\\n Cholesterol, Total   210 mg/dl\\n Triglycerides  236 mg/dl\\n HDL Cholesterol 36\\n LDL Cholesterol 127\\n \\n WeServeEveryone Clinic\\tMarch 24, 2011\\n 1111 First Street California\\n 111-111-11111   Fax: 111-111-1111\\tPage 2\\n Chart Summary\\n Adam Pie\\t \\n Male DOB: 08/08/1948\\n 0000-88888\\n Ins: Commercial xxxxx\\tHome: 888-888-8888\\n Flowsheet\\n \\n  \\tDate 12/18/2010\\n HEIGHT  (in)\\t70\\n WEIGHT (lb)\\t190\\n TEMPERATURE (deg F)\\t98\\n TEMP SITE\\toral\\n PULSE RATE (/min)\\t72\\n PULSE RHYTHM\\t \\n RESP RATE (/min)\\t16\\n BP SYSTOLIC (mm Hg)\\t158\\n BP DIASTOLIC (mm Hg)\\t90\\n CHOLESTEROL (mg/dL)\\t \\n HDL (mg/dL)\\t127\\n LDL (mg/dL)\\t \\n BG RANDOM  (mg/dL)\\t \\n CXR\\t \\n EKG\\t \\n PAP SMEAR\\t \\n BREAST EXAM\\t \\n MAMMOGRAM\\t \\n HEMOCCULT \\tneg\\n FLU VAX \\t0.5 ml g\\n PNEUMOVAX\\t0.5 ml g\\n TD BOOSTER\\t0.5 ml g\\n Foot Exam\\tComplete\\n Eye Exam\\tComplete'"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strtemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
